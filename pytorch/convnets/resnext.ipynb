{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORnUaPxFxM4wZ82SYTNJTq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IANGECHUKI176/deeplearning/blob/main/pytorch/convnets/resnext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "original [paper](https://arxiv.org/pdf/1611.05431.pdf)"
      ],
      "metadata": {
        "id": "fheKyIGYO-Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNeXt is a simple, highly modularized network architecture for image classification. The\n",
        "network is constructed by repeating a building block that aggregates a set of transformations\n",
        "with the same topology. The simple design results in a homogeneous, multi-branch architecture\n",
        "that has only a few hyper-parameters to set. This strategy exposes a new dimension, which is\n",
        "referred as “cardinality” (the size of the set of transformations), as an essential factor in\n",
        "addition to the dimensions of depth and width.\n",
        "\n",
        "We can think of cardinality as the set of separate conv block representing same complexity as\n",
        "when those blocks are combined together to make a single block.\n",
        "\n",
        "Blog:\n",
        "#### Citation ####\n",
        "\n",
        "PyTorch Code: https://github.com/Mayurji/Image-Classification-PyTorch/blob/main/ResNeXt.py\n",
        "\n",
        "@article{Xie2016,\n",
        "  title={Aggregated Residual Transformations for Deep Neural Networks},\n",
        "  author={Saining Xie and Ross Girshick and Piotr Dollár and Zhuowen Tu and Kaiming He},\n",
        "  journal={arXiv preprint arXiv:1611.05431},\n",
        "  year={2016}\n",
        "}\n"
      ],
      "metadata": {
        "id": "X62kDNn1GKMU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1XcOJKlilmf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    '''Grouped convolution block.'''\n",
        "    expansion = 2\n",
        "    def __init__(self,in_planes,cardinality = 32,bottleneck_width = 4,stride = 1):\n",
        "        super(Block,self).__init__()\n",
        "        group_width = cardinality * bottleneck_width\n",
        "        self.conv1 = nn.Conv2d(in_planes,group_width,kernel_size = 1,bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(group_width)\n",
        "        \"\"\"group=cardinality, it divides the out_channel by 32(cardinality) i.e. thus, divides channel 128 into 4\"\"\"\n",
        "        self.conv2 = nn.Conv2d(group_width,group_width,kernel_size = 3,stride = stride,padding = 1,groups = cardinality,bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(group_width)\n",
        "        self.conv3 = nn.Conv2d(group_width,self.expansion * group_width,kernel_size = 1,bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * group_width)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * group_width:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes,self.expansion * group_width,kernel_size = 1,stride = stride,bias = False),\n",
        "                nn.BatchNorm2d(self.expansion * group_width)\n",
        "            )\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        short_cut = self.shortcut(x)\n",
        "        out = out + short_cut\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "BRfC-aTtvZlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# blk = Block(3)\n",
        "# summary(blk,(3,224,224))"
      ],
      "metadata": {
        "id": "Sv4k0KqW2U8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNeXt(nn.Module):\n",
        "    def __init__(self,num_blocks,cardinality,bottleneck_width,num_classes = 10):\n",
        "        super(ResNeXt,self).__init__()\n",
        "        self.cardinality = cardinality\n",
        "        self.bottleneck_width = bottleneck_width\n",
        "\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3,64,kernel_size = 1,bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.layer1 = self._make_layers(num_blocks[0],1)\n",
        "        self.layer2 = self._make_layers(num_blocks[1],2)\n",
        "        self.layer3 = self._make_layers(num_blocks[2],2)\n",
        "\n",
        "        #self.layer4  = self._make_layers(num_blocks[3],2)\n",
        "        print('bottleneck width',self.bottleneck_width)\n",
        "        self.linear = nn.Linear(cardinality*self.bottleneck_width,num_classes)\n",
        "    def _make_layers(self,num_blocks,stride):\n",
        "        strides = [stride] + [1]*(num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(Block(self.in_planes,self.cardinality,self.bottleneck_width,stride))\n",
        "            self.in_planes = Block.expansion * self.cardinality * self.bottleneck_width\n",
        "        # Increase bottleneck_width by 2 after each stage\n",
        "        self.bottleneck_width *= 2\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        #out = self.layer4(out)\n",
        "        out = F.adaptive_avg_pool2d(out,1)\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "6yPUW2pr3Una"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# blk1 = ResNeXt(num_blocks= [3, 4, 6, 3], cardinality=32, bottleneck_width=4)\n",
        "# summary(blk1,(3,224,224))"
      ],
      "metadata": {
        "id": "reuhVgFg7odm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnext50():\n",
        "    \"\"\" return a resnext50(c32x4d) network\n",
        "    \"\"\"\n",
        "    return ResNeXt(num_blocks= [3, 4, 6, 3], cardinality=32, bottleneck_width=4)\n",
        "\n",
        "def resnext101():\n",
        "    \"\"\" return a resnext101(c32x4d) network\n",
        "    \"\"\"\n",
        "    return ResNeXt(num_blocks=  [3, 4, 23, 3], cardinality=32, bottleneck_width=4)\n",
        "\n",
        "def resnext152():\n",
        "    \"\"\" return a resnext101(c32x4d) network\n",
        "    \"\"\"\n",
        "    return ResNeXt(num_blocks= [3, 4, 36, 3], cardinality=32, bottleneck_width=4)"
      ],
      "metadata": {
        "id": "srk7-opTMp_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# alternative implementation on this : [github](https://github.com/YeonwooSung/PyTorch_CNN_Architectures/blob/master/models/resnext.py)"
      ],
      "metadata": {
        "id": "97gHxVHNP4GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CARDINALITY = 32 #How many groups a feature map was splitted into\n",
        "DEPTH = 4\n",
        "BASEWIDTH = 64\n",
        "#\"\"\"The grouped convolutional layer in Fig. 3(c) performs 32 groups\n",
        "#of convolutions whose input and output channels are 4-dimensional.\n",
        "#The grouped convolutional layer concatenates them as the outputs\n",
        "#of the layer.\"\"\"\n",
        "class ResNextBottleNeckC(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,stride):\n",
        "        super(ResNextBottleNeckC,self).__init__()\n",
        "\n",
        "        intermediate_channels = CARDINALITY * ((DEPTH * out_channels) // BASEWIDTH)\n",
        "        #\"\"\"We note that the input/output width of the template is fixed as\n",
        "        #256-d (Fig. 3), We note that the input/output width of the template\n",
        "        #is fixed as 256-d (Fig. 3), and all widths are dou- bled each time\n",
        "        #when the feature map is subsampled (see Table 1).\"\"\"\n",
        "        self.split_transforms = nn.Sequential(\n",
        "            nn.Conv2d(in_channels,intermediate_channels,kernel_size = 1,groups = CARDINALITY,bias = False),\n",
        "            nn.BatchNorm2d(intermediate_channels),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Conv2d(intermediate_channels,intermediate_channels,kernel_size = 3,stride = stride,groups = CARDINALITY,padding = 1,bias = False),\n",
        "            nn.BatchNorm2d(intermediate_channels),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Conv2d(intermediate_channels,out_channels*4,kernel_size = 1,bias = False),\n",
        "            nn.BatchNorm2d(out_channels*4)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels*4:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels,out_channels * 4,kernel_size = 1,stride = stride,bias = False),\n",
        "                nn.BatchNorm2d(out_channels * 4)\n",
        "            )\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.split_transforms(x)\n",
        "        shortcut = self.shortcut(x)\n",
        "        out = F.relu(out + shortcut)\n",
        "        return out"
      ],
      "metadata": {
        "id": "QQrHuX7XQDuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNext(nn.Module):\n",
        "    def __init__(self,block,num_blocks,n_classes = 10):\n",
        "        super(ResNext,self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3,64,kernel_size = 3,stride = 1,padding = 1,bias = False),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU(inplace = True))\n",
        "        self.conv2 = self._make_layers(block,num_blocks[0],64,1)\n",
        "        self.conv3 = self._make_layers(block,num_blocks[1],128,2)\n",
        "        self.conv4 = self._make_layers(block,num_blocks[2],256,2)\n",
        "        self.conv5 = self._make_layers(block,num_blocks[3],512,2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.linear = nn.Linear(512 * 4,n_classes)\n",
        "\n",
        "    def _make_layers(self,block,num_blocks,out_channels,stride):\n",
        "        strides = [stride] + [1]*(num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels,out_channels,stride))\n",
        "            self.in_channels = out_channels * 4\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self,x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = self.linear(out)"
      ],
      "metadata": {
        "id": "D6a2gixJXPLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnext50():\n",
        "    \"\"\" return a resnext50(c32x4d) network\n",
        "    \"\"\"\n",
        "    return ResNext(ResNextBottleNeckC, [3, 4, 6, 3])\n",
        "\n",
        "def resnext101():\n",
        "    \"\"\" return a resnext101(c32x4d) network\n",
        "    \"\"\"\n",
        "    return ResNext(ResNextBottleNeckC, [3, 4, 23, 3])\n",
        "\n",
        "def resnext152():\n",
        "    \"\"\" return a resnext101(c32x4d) network\n",
        "    \"\"\"\n",
        "    return ResNext(ResNextBottleNeckC, [3, 4, 36, 3])"
      ],
      "metadata": {
        "id": "rgCFk1PWae-b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}