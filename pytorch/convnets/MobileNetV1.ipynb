{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXcKeKIL4rK+lJyyGgRhSw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IANGECHUKI176/deeplearning/blob/main/pytorch/convnets/MobileNetV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eVFmCHfunIYS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNetV1 [paper](https://arxiv.org/pdf/1704.04861v1.pdf)\n",
        "\n",
        "A convolutional neural network with large number of layers is expensive, both interms of memory and the\n",
        "hardware requirement for inference and thus deploying such models in mobile devices is not feasible.\n",
        "\n",
        "To overcome the above challenge, a group of researchers from Google built a neural network model\n",
        "optimized for mobile devices referred as MobileNet. Underlying idea of mobilenet is depthwise\n",
        "seperable convolutions consisting of depthwise and a pointwise convolution to build lighter models.\n",
        "\n",
        "MobileNet introduces two hyperparameters\n",
        "\n",
        "* Width Multiplier\n",
        "\n",
        "Width muliplier (denoted by α) is a global hyperparameter that is used to construct smaller and less\n",
        "computionally expensive models.Its value lies between 0 and 1.For a given layer and value of α, the\n",
        "number of input channels 'M' becomes α * M and the number of output channels 'N' becomes α * N hence\n",
        "reducing the cost of computation and size of the model at the cost of performance.The computation cost\n",
        "and number of parameters decrease roughly by a factor of α2.Some commonly used values of α are 1,0.75,0.5,0.25.\n",
        "\n",
        "* Resolution Multiplier\n",
        "\n",
        "The second parameter introduced in MobileNets is called resolution multiplier and is denoted by ρ.This\n",
        "hyperparameter is used to decrease the resolution of the input image and this subsequently reduces the\n",
        "input to every layer by the same factor. For a given value of ρ the resolution of the input image becomes\n",
        "224 * ρ. This reduces the computational cost by a factor of ρ2.\n",
        "\n",
        "The above parameters helps in trade-off between latency (speed of inference) and accuracy.\n",
        "\n",
        "MobileNet is 28 layers neural net represented by both the depthwise convolution and pointwise convolution."
      ],
      "metadata": {
        "id": "mgbEnKDPKETl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNetV1(nn.Module):\n",
        "    def __init__(self,c_in,n_classes):\n",
        "        super(MobileNetV1,self).__init__()\n",
        "\n",
        "        def conv_bn(c_in,c_out,stride):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(c_in,c_out,kernel_size = 3,stride = stride,padding = 1,bias = False),\n",
        "                nn.BatchNorm2d(c_out),\n",
        "                nn.ReLU(inplace = True)\n",
        "            )\n",
        "        def conv_dw(c_in,c_out,stride):\n",
        "            return nn.Sequential(\n",
        "                #dw\n",
        "                nn.Conv2d(c_in,c_in,kernel_size = 3,stride = stride , padding = 1,groups = c_in,bias = False),\n",
        "                nn.BatchNorm2d(c_in),\n",
        "                nn.ReLU(inplace = True),\n",
        "\n",
        "                #pw\n",
        "                nn.Conv2d(c_in,c_out,kernel_size = 1,stride = 1,padding = 0,bias = False),\n",
        "                nn.BatchNorm2d(c_out),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.model = nn.Sequential(\n",
        "            conv_bn(c_in,32,2),\n",
        "            conv_dw(32,64,1),\n",
        "            conv_dw(64,128,2),\n",
        "            conv_dw(128,128,1),\n",
        "            conv_dw(128,256,2),\n",
        "            conv_dw(256,256,1),\n",
        "            conv_dw(256,512,2),\n",
        "            conv_dw(512,512,1),\n",
        "            conv_dw(512,512,1),\n",
        "            conv_dw(512,512,1),\n",
        "            conv_dw(512,512,1),\n",
        "            conv_dw(512,512,1),\n",
        "            conv_dw(512,1024,2),\n",
        "            conv_dw(1024,1024,1),\n",
        "            nn.AdaptiveAvgPool2d(1) # or nn.AvgPool2d(7)\n",
        "        )\n",
        "        self.fc = nn.Linear(1024,n_classes)\n",
        "    def forward(self,x):\n",
        "        out = self.model(x)\n",
        "        out = out.view(-1,1024)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "HYrQsT4eKF0f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "device  = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "blk = MobileNetV1(3,10)\n",
        "\n",
        "summary(blk,(3,224,224))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkdNbewPVEMF",
        "outputId": "b9e17e68-284c-43fb-fd39-3de6d1e827eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "              ReLU-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "              ReLU-6         [-1, 32, 112, 112]               0\n",
            "            Conv2d-7         [-1, 64, 112, 112]           2,048\n",
            "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
            "              ReLU-9         [-1, 64, 112, 112]               0\n",
            "           Conv2d-10           [-1, 64, 56, 56]             576\n",
            "      BatchNorm2d-11           [-1, 64, 56, 56]             128\n",
            "             ReLU-12           [-1, 64, 56, 56]               0\n",
            "           Conv2d-13          [-1, 128, 56, 56]           8,192\n",
            "      BatchNorm2d-14          [-1, 128, 56, 56]             256\n",
            "             ReLU-15          [-1, 128, 56, 56]               0\n",
            "           Conv2d-16          [-1, 128, 56, 56]           1,152\n",
            "      BatchNorm2d-17          [-1, 128, 56, 56]             256\n",
            "             ReLU-18          [-1, 128, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "             ReLU-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]           1,152\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "             ReLU-24          [-1, 128, 28, 28]               0\n",
            "           Conv2d-25          [-1, 256, 28, 28]          32,768\n",
            "      BatchNorm2d-26          [-1, 256, 28, 28]             512\n",
            "             ReLU-27          [-1, 256, 28, 28]               0\n",
            "           Conv2d-28          [-1, 256, 28, 28]           2,304\n",
            "      BatchNorm2d-29          [-1, 256, 28, 28]             512\n",
            "             ReLU-30          [-1, 256, 28, 28]               0\n",
            "           Conv2d-31          [-1, 256, 28, 28]          65,536\n",
            "      BatchNorm2d-32          [-1, 256, 28, 28]             512\n",
            "             ReLU-33          [-1, 256, 28, 28]               0\n",
            "           Conv2d-34          [-1, 256, 14, 14]           2,304\n",
            "      BatchNorm2d-35          [-1, 256, 14, 14]             512\n",
            "             ReLU-36          [-1, 256, 14, 14]               0\n",
            "           Conv2d-37          [-1, 512, 14, 14]         131,072\n",
            "      BatchNorm2d-38          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-39          [-1, 512, 14, 14]               0\n",
            "           Conv2d-40          [-1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-41          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-42          [-1, 512, 14, 14]               0\n",
            "           Conv2d-43          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-44          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-45          [-1, 512, 14, 14]               0\n",
            "           Conv2d-46          [-1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-47          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-48          [-1, 512, 14, 14]               0\n",
            "           Conv2d-49          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-50          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-51          [-1, 512, 14, 14]               0\n",
            "           Conv2d-52          [-1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-53          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-54          [-1, 512, 14, 14]               0\n",
            "           Conv2d-55          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-56          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-57          [-1, 512, 14, 14]               0\n",
            "           Conv2d-58          [-1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-59          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-60          [-1, 512, 14, 14]               0\n",
            "           Conv2d-61          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-62          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-63          [-1, 512, 14, 14]               0\n",
            "           Conv2d-64          [-1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-65          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-66          [-1, 512, 14, 14]               0\n",
            "           Conv2d-67          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-68          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-69          [-1, 512, 14, 14]               0\n",
            "           Conv2d-70            [-1, 512, 7, 7]           4,608\n",
            "      BatchNorm2d-71            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-72            [-1, 512, 7, 7]               0\n",
            "           Conv2d-73           [-1, 1024, 7, 7]         524,288\n",
            "      BatchNorm2d-74           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-75           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-76           [-1, 1024, 7, 7]           9,216\n",
            "      BatchNorm2d-77           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-78           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-79           [-1, 1024, 7, 7]       1,048,576\n",
            "      BatchNorm2d-80           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-81           [-1, 1024, 7, 7]               0\n",
            "AdaptiveAvgPool2d-82           [-1, 1024, 1, 1]               0\n",
            "           Linear-83                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 3,217,226\n",
            "Trainable params: 3,217,226\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 115.43\n",
            "Params size (MB): 12.27\n",
            "Estimated Total Size (MB): 128.27\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(4,3,224,224)\n",
        "out = blk(input)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAS0YNSWXZSJ",
        "outputId": "d4777c42-e33e-448c-80b2-80bdc14666a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}