{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5KtQlrXoGJ9FMq5Kk4Sas",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IANGECHUKI176/deeplearning/blob/main/pytorch/convnets/SENet(SqueezeExcitationNet).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Squeeze and Excitation Network\n",
        "\n",
        "A typical convolution network has kernels running through image channels and combining\n",
        "the feature maps generated per channel. For each channel, we'll have separate kernel which\n",
        "learns the weights through backpropagation.\n",
        "\n",
        "The idea is to understand the interdependencies between channels of the images by explicitly\n",
        "modeling on it and hence to make the network sensitive to informative features which is further\n",
        "exploited in the next set of transformation.\n",
        "\n",
        "* Squeeze(Global Information Embedding) operation converts feature maps into single value per channel.\n",
        "* Excitation(Adaptive Recalibration) operation converts this single value into per-channel weight.\n",
        "\n",
        "Squeeze turns (C x H x W) into (C x 1 x 1) using Global Average Pooling.\n",
        "Excitation turns (C x 1 x 1) into (C x H x W) channel weights using 2 FC layer with activation function\n",
        "inbetween, then which is expanded as same size as input.\n",
        "\n",
        "Rescale the output from excitation operation into feature maps as earlier.\n",
        "\n",
        "Based on the depth of the network, the role played by SE operation is differs. At early layers,\n",
        "it excites shared low level representation irrespective of the classes. But in later stage, SE\n",
        "network responds differently based input class.\n",
        "\n",
        "SE Block is simple and is added with existing CNN architecture to enhance the performance like\n",
        "ResNet or Inception V1 etc."
      ],
      "metadata": {
        "id": "fsBMSu-B7sLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used `SEResNet` in this example\n",
        "\n",
        "> https://github.com/kuangliu/pytorch-cifar/blob/master/models/senet.py\n",
        "\n",
        "> https://github.com/YeonwooSung/PyTorch_CNN_Architectures/blob/master/models/senet.py"
      ],
      "metadata": {
        "id": "JkdiBjq2FzxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts_XYj-M7Hs7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Note: if you are using `F.adaptive_avg_pool2d(1)` you dont mention the size of width and height of incoming input\n",
        "\n",
        "> if you are using `F.avg_pool2d(out,out.size(2))` you have to mention the size of width or height"
      ],
      "metadata": {
        "id": "i4-S8AtRF30v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self,ch_in,ch_out,stride = 1):\n",
        "        super(BasicBlock,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(ch_in,ch_out,kernel_size=3 ,stride = stride,padding = 1,bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(ch_out)\n",
        "        self.conv2 = nn.Conv2d(ch_out,ch_out,kernel_size = 3,stride = 1 , padding = 1,bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(ch_out)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or ch_in != ch_out:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(ch_in,ch_out,kernel_size = 1,stride = stride,bias = False),\n",
        "                nn.BatchNorm2d(ch_out)\n",
        "            )\n",
        "        #SE\n",
        "        self.fc1 = nn.Conv2d(ch_out,ch_out// 16,kernel_size = 1)\n",
        "        self.fc2 = nn.Conv2d(ch_out // 16,ch_out,kernel_size = 1)\n",
        "    def forward(self,x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        #squeeze\n",
        "        w = F.avg_pool2d(out,out.size(2))\n",
        "        #w = F.adaptive_avg_pool2d(out,1)\n",
        "\n",
        "        w = F.relu(self.fc1(w))\n",
        "        w = F.sigmoid(self.fc2(w))\n",
        "        #excitation\n",
        "        out = out * w\n",
        "\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Pm-8mb81g7M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "HQIRdhuVCCZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk0 = BasicBlock(3,64,stride = 2)\n",
        "summary(blk0,(3,224,224))"
      ],
      "metadata": {
        "id": "5jqMc0kpEOyq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8da4d3-dd45-4538-85cc-d9e5aa721d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           1,728\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "            Conv2d-3         [-1, 64, 112, 112]          36,864\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5              [-1, 4, 1, 1]             260\n",
            "            Conv2d-6             [-1, 64, 1, 1]             320\n",
            "            Conv2d-7         [-1, 64, 112, 112]             192\n",
            "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
            "================================================================\n",
            "Total params: 39,748\n",
            "Trainable params: 39,748\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 36.75\n",
            "Params size (MB): 0.15\n",
            "Estimated Total Size (MB): 37.48\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PreActBlock(nn.Module):\n",
        "    def __init__(self,ch_in,ch_out,stride = 1):\n",
        "        super(PreActBlock,self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(ch_in)\n",
        "        self.conv1 = nn.Conv2d(ch_in,ch_out,kernel_size = 3,stride = stride,padding = 1,bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(ch_out)\n",
        "        self.conv2 = nn.Conv2d(ch_out,ch_out,kernel_size = 3,stride = 1,padding = 1,bias = False)\n",
        "\n",
        "\n",
        "        if stride != 1 or ch_in != ch_out:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(ch_in,ch_out,kernel_size = 1,stride = stride ,bias = False)\n",
        "            )\n",
        "        #se\n",
        "        self.fc1 = nn.Conv2d(ch_out,ch_out//16,kernel_size = 1)\n",
        "        self.fc2 = nn.Conv2d(ch_out//16,ch_out,kernel_size = 1)\n",
        "    def forward(self,x):\n",
        "        out = F.relu(self.bn1(x))\n",
        "        shortcut = self.shortcut(x) if hasattr(self,'shortcut') else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "\n",
        "\n",
        "        #squeeze\n",
        "        #w = F.adaptive_avg_pool2d(out,1)\n",
        "        w = F.avg_pool2d(out,out.size(2))\n",
        "        w = F.relu(self.fc1(w))\n",
        "        w = F.sigmoid(self.fc2(w))\n",
        "        #exitation\n",
        "        out = out * w\n",
        "        out += shortcut\n",
        "\n",
        "        return out\n",
        "        #excitation"
      ],
      "metadata": {
        "id": "X7U7645TJWI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk2 = PreActBlock(3,32,stride = 1)\n",
        "summary(blk2,(3,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPxqrH9seXgo",
        "outputId": "e101e713-e91c-4ea2-d1e4-5240a886d1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       BatchNorm2d-1          [-1, 3, 224, 224]               6\n",
            "            Conv2d-2         [-1, 32, 224, 224]              96\n",
            "            Conv2d-3         [-1, 32, 224, 224]             864\n",
            "       BatchNorm2d-4         [-1, 32, 224, 224]              64\n",
            "            Conv2d-5         [-1, 32, 224, 224]           9,216\n",
            "            Conv2d-6              [-1, 2, 1, 1]              66\n",
            "            Conv2d-7             [-1, 32, 1, 1]              96\n",
            "================================================================\n",
            "Total params: 10,408\n",
            "Trainable params: 10,408\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 50.15\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 50.76\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SENet(nn.Module):\n",
        "    def __init__(self,block,num_blocks,n_classes):\n",
        "        super(SENet,self).__init__()\n",
        "        self.ch_in = 64\n",
        "        self.conv1 = nn.Conv2d(3,64,kernel_size = 3,stride = 1,padding = 1,bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.layer1 = self._make_layers(block,64,num_blocks[0],stride = 1)\n",
        "        self.layer2 = self._make_layers(block,128,num_blocks[1],stride = 2)\n",
        "        self.layer3 = self._make_layers(block,256,num_blocks[2],stride = 2)\n",
        "        self.layer4 = self._make_layers(block,512,num_blocks[3],stride = 2)\n",
        "        self.linear = nn.Linear(512,n_classes)\n",
        "    def _make_layers(self,block,ch_out,num_residuals,stride):\n",
        "        strides = [stride] + [1]*(num_residuals - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.ch_in,ch_out,stride))\n",
        "            self.ch_in = ch_out\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self,x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.adaptive_avg_pool2d(out,1)\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "yIGKAEUlmeqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SENet(PreActBlock, [2,2,2,2],10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roUDqPMCKcsR",
        "outputId": "55003be4-906f-455b-db4d-15c033a7e0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SENet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      )\n",
              "      (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      )\n",
              "      (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      )\n",
              "      (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SENet18():\n",
        "    return SENet(PreActBlock, [2,2,2,2],10)\n",
        "\n",
        "def seresnet34():\n",
        "    return SENet(PreActBlock, [3, 4, 6, 3],10)\n",
        "# for renet50 ,resnet101,reenset152 use a bottleneck\n",
        "net = SENet18()\n",
        "# y = net(torch.randn(1,3,32,32))\n",
        "#     print(y.size())\n",
        "summary(net,(3,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NwwV7reCDGE",
        "outputId": "1d38bd7b-765d-4dfd-dd86-5d8fc9f27f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,728\n",
            "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
            "       BatchNorm2d-3         [-1, 64, 224, 224]             128\n",
            "            Conv2d-4         [-1, 64, 224, 224]          36,864\n",
            "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
            "            Conv2d-6         [-1, 64, 224, 224]          36,864\n",
            "            Conv2d-7              [-1, 4, 1, 1]             260\n",
            "            Conv2d-8             [-1, 64, 1, 1]             320\n",
            "       PreActBlock-9         [-1, 64, 224, 224]               0\n",
            "      BatchNorm2d-10         [-1, 64, 224, 224]             128\n",
            "           Conv2d-11         [-1, 64, 224, 224]          36,864\n",
            "      BatchNorm2d-12         [-1, 64, 224, 224]             128\n",
            "           Conv2d-13         [-1, 64, 224, 224]          36,864\n",
            "           Conv2d-14              [-1, 4, 1, 1]             260\n",
            "           Conv2d-15             [-1, 64, 1, 1]             320\n",
            "      PreActBlock-16         [-1, 64, 224, 224]               0\n",
            "      BatchNorm2d-17         [-1, 64, 224, 224]             128\n",
            "           Conv2d-18        [-1, 128, 112, 112]           8,192\n",
            "           Conv2d-19        [-1, 128, 112, 112]          73,728\n",
            "      BatchNorm2d-20        [-1, 128, 112, 112]             256\n",
            "           Conv2d-21        [-1, 128, 112, 112]         147,456\n",
            "           Conv2d-22              [-1, 8, 1, 1]           1,032\n",
            "           Conv2d-23            [-1, 128, 1, 1]           1,152\n",
            "      PreActBlock-24        [-1, 128, 112, 112]               0\n",
            "      BatchNorm2d-25        [-1, 128, 112, 112]             256\n",
            "           Conv2d-26        [-1, 128, 112, 112]         147,456\n",
            "      BatchNorm2d-27        [-1, 128, 112, 112]             256\n",
            "           Conv2d-28        [-1, 128, 112, 112]         147,456\n",
            "           Conv2d-29              [-1, 8, 1, 1]           1,032\n",
            "           Conv2d-30            [-1, 128, 1, 1]           1,152\n",
            "      PreActBlock-31        [-1, 128, 112, 112]               0\n",
            "      BatchNorm2d-32        [-1, 128, 112, 112]             256\n",
            "           Conv2d-33          [-1, 256, 56, 56]          32,768\n",
            "           Conv2d-34          [-1, 256, 56, 56]         294,912\n",
            "      BatchNorm2d-35          [-1, 256, 56, 56]             512\n",
            "           Conv2d-36          [-1, 256, 56, 56]         589,824\n",
            "           Conv2d-37             [-1, 16, 1, 1]           4,112\n",
            "           Conv2d-38            [-1, 256, 1, 1]           4,352\n",
            "      PreActBlock-39          [-1, 256, 56, 56]               0\n",
            "      BatchNorm2d-40          [-1, 256, 56, 56]             512\n",
            "           Conv2d-41          [-1, 256, 56, 56]         589,824\n",
            "      BatchNorm2d-42          [-1, 256, 56, 56]             512\n",
            "           Conv2d-43          [-1, 256, 56, 56]         589,824\n",
            "           Conv2d-44             [-1, 16, 1, 1]           4,112\n",
            "           Conv2d-45            [-1, 256, 1, 1]           4,352\n",
            "      PreActBlock-46          [-1, 256, 56, 56]               0\n",
            "      BatchNorm2d-47          [-1, 256, 56, 56]             512\n",
            "           Conv2d-48          [-1, 512, 28, 28]         131,072\n",
            "           Conv2d-49          [-1, 512, 28, 28]       1,179,648\n",
            "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-51          [-1, 512, 28, 28]       2,359,296\n",
            "           Conv2d-52             [-1, 32, 1, 1]          16,416\n",
            "           Conv2d-53            [-1, 512, 1, 1]          16,896\n",
            "      PreActBlock-54          [-1, 512, 28, 28]               0\n",
            "      BatchNorm2d-55          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-56          [-1, 512, 28, 28]       2,359,296\n",
            "      BatchNorm2d-57          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-58          [-1, 512, 28, 28]       2,359,296\n",
            "           Conv2d-59             [-1, 32, 1, 1]          16,416\n",
            "           Conv2d-60            [-1, 512, 1, 1]          16,896\n",
            "      PreActBlock-61          [-1, 512, 28, 28]               0\n",
            "           Linear-62                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,260,354\n",
            "Trainable params: 11,260,354\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 551.27\n",
            "Params size (MB): 42.95\n",
            "Estimated Total Size (MB): 594.79\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net(torch.randn(2,3,224,224)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM-tvAXSEar1",
        "outputId": "8d98d8a3-6b0e-4756-ef79-04db4e411bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    }
  ]
}